<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Info on Class Homepage</title>
    <link>/docs/course-info/</link>
    <description>Recent content in Course Info on Class Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="/docs/course-info/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Course Overview</title>
      <link>/docs/course-info/course-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/course-info/course-overview/</guid>
      <description>Course Goals # Analyze NLP techniques and apply them to text data. The course is divided into three main categories:
Preprocessing: Demonstrate how to clean and integrate text data
Processing: Apply NLP algorithms on your pre-processed data to perform different tasks
Post-processing: Evaluate your developed NLP models.
Solve problems with real datasets Apply practical know-how (useful for jobs, research) through significant hands-on programming assignments
Course Pre- and/or Co-Requisites # Review our &amp;ldquo;warnings&amp;rdquo; before taking this course.</description>
    </item>
    
    <item>
      <title>Instructor and TAs</title>
      <link>/docs/course-info/instructors-and-tas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/course-info/instructors-and-tas/</guid>
      <description> Instructors and TAs # Instructor # Max Mahdi Roozbahani mahdir@gatech.edu https://mahdi-roozbahani.github.io/ Wafa Louhichi wlouhichi3@gatech.edu https://www.linkedin.com/in/wafa-louhichi/ Nimisha Roy nroy9@gatech.edu https://nimisharoy9.wixsite.com/myportfolio Head TAs # Ruslina Utomo rutomo6@gatech.edu TAs # Faizan Hasan fhasan8@gatech.edu Ashwin Pathak apathak60@gatech.edu Mehul Soni mehul.soni918@gatech.edu Daanish M Mohammed dmohammed7@gatech.edu Ruijia Wang rwang@gatech.edu Rohit Das rohdas@gatech.edu </description>
    </item>
    
    <item>
      <title>Course Schedule</title>
      <link>/docs/course-info/course-schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/course-info/course-schedule/</guid>
      <description> Schedule # Important
All deadline and due dates in this course will be at 23:59 ET.
Scroll horizontally to see the full schedule table on mobile devices Astericks (*) indicate that the lecture slides/notes are available.
Week Dates Topics Homework Quizzes Project Readings 1 8/21 - 8/25 Course introduction Text data preprocessing: Normalization, lemmatization, stemming, stop words removal&amp;hellip; 2 8/28 - 9/01 Text Representations: One hot encoding BoW (frequency counting) TF-IDF HW1 out 9/01 Quiz 0 | Knowledge-based | out 8/25 - due 9/01 3 9/04 - 9/08 Labor Day Holiday Classification Introduction Naive Bayes Classification Model Evaluation: accuracy, precision, recall, confusion matrix Quiz 1 | week 1 and 2| out 9/01 - due 9/06 4 9/11 - 9/15 Focus on HW1 Quiz 2 | week 3| out 9/08 - due 9/12 5 9/18 - 9/22 Logistic Regression SVM Perceptron *Density Estimation (*Notes L10-B) HW1 due 9/22 HW2 out 9/22 6 9/25 - 9/29 SVD (Dimensionality Reduction) + Co-occurrence embeddings Glove Quiz 3 | week 5| out 9/22 - due 9/26 GloVe: Global Vectors for Word Representation 7 10/2 - 10/6 Focus on HW2 8 10/9 - 10/13 Fall break Neural Network (fully connected) Word2vec: CBoW, Skip-Gram Quiz 4 | week 6| out 10/06 - due 10/12 NN Playground Interactive NN initialization; The role of a hidden layer; Back propagation numerical example; More detailed introduction; Efficient Estimation of Word Representations in Vector Space 9 10/16 - 10/20 CNN (use the chart, provide some explainability RNN (quick overview as an intro to LSTM) HW2 due 10/20 HW3 out 10/20 Quiz 5 | week 8| out 10/13 - due 10/17 CNN Live Demo; A guide to an efficient way to build CNN and optimize its hyper-parameters; Back Propagation in CNN; Transfer learning in CNN; 10 10/23 - 10/27 Focus on HW3 Quiz 6 | week 9| out 10/20 - due 10/24 11 10/30 - 11/03 LSTM and GRU LSTM + Attention (Focus on Attention mechanism) HW3 due 11/03 HW4 out 11/03 12 11/06 - 11/10 Transformer models Examples: BERT(Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer) Quiz 7 | week 11| out 11/03 - due 11/07 Attention Is All You Need; BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding; 13 11/13 - 11/17 Sequence Labelling: POS Tagging Sequence Labelling: NER Quiz 8 | week 12| out 11/10 - due 11/14 14 11/20 - 11/24 Unsupervised Models Student Recess Holiday Thanksgiving Break Quiz 9 | week 13| out 11/17 - due 11/21 15 11/27 - 12/01 Topic Modeling (Latent Semantic Indexing, LDA (Latent Dirichlet Allocation) HW4 due 12/01 Quiz 10 | week 14 and 15| out 11/30 - due 12/04 </description>
    </item>
    
  </channel>
</rss>
